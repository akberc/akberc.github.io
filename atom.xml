<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Akber Choudhry]]></title>
  <link href="http://www.akber.com/atom.xml" rel="self"/>
  <link href="http://www.akber.com/"/>
  <updated>2013-12-24T03:13:11+00:00</updated>
  <id>http://www.akber.com/</id>
  <author>
    <name><![CDATA[Akber Choudhry]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Is Ceylon Enterprise Ready?]]></title>
    <link href="http://www.akber.com/is-ceylon-enterprise-ready"/>
    <updated>2013-10-04T18:30:51+01:00</updated>
    <id>http://www.akber.com/is-ceylon-enterprise-ready</id>
    <content type="html"><![CDATA[<p>Ceylon is an up-and-coming JVM language with some very interesting features.  I took it for a spin and experiences are posted at <a href="http://java.dzone.com/articles/ceylon-enterprise-ready">http://java.dzone.com/articles/ceylon-enterprise-ready</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fluent HttpClient for APIs]]></title>
    <link href="http://www.akber.com/fluent-httpclient-for-apis"/>
    <updated>2013-04-20T18:30:51+01:00</updated>
    <id>http://www.akber.com/fluent-httpclient-for-apis</id>
    <content type="html"><![CDATA[<p>The new HttpClient provides a fluent interface that is quite intuitive. However, any non-trivial implementation soon starts to miss the flexibility of configuring the connection manager. As a pre-configured HttpClient can be passed into the fluent Executor, it is not necessary to configure it each time.</p>

<p>posted at <a href="http://java.dzone.com/tips/fluency-and-control-httpclient">http://java.dzone.com/tips/fluency-and-control-httpclient</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bloatware Destroying Android Experience]]></title>
    <link href="http://www.akber.com/bloatware-destroying-android-experience"/>
    <updated>2012-10-23T14:11:36+01:00</updated>
    <id>http://www.akber.com/bloatware-destroying-android-experience</id>
    <content type="html"><![CDATA[<p>Samsung makes beautiful handsets. Can Samsung please stick to doing what they do best? If you were that good at software, would you be latching on to the open-source Android in the first place?  And this goes for vendors other than Samsung as well.</p>

<!-- more -->


<p><a href="http://www.wired.com/gadgetlab/2010/07/bloatware-android-phones/"><img src="http://www.wired.com/images_blogs/gadgetlab/2010/07/samsung_galaxy1.jpg" alt="" /></a></p>

<p>I always buy my phones unlocked, so it is not the carrier that is at fault.  I am certain it is the device vendor, especially if the apps mostly begin with &rsquo;S&#8217;!  On returning home from buying a shiny new Galaxy Note II, I had to spend half a day Googling which bloatware apps were safe to remove, disabling the ones that could not be removed at all (Android feature?). The other half was spent monitoring background bandwidth usage and disabling it.</p>

<p>It is not only me that is not enjoying this &lsquo;de-boxing&rsquo; experience that spoils the un-boxing fun of purchasing a new device.  Other people are up in arms over this practice as well: <a href="http://www.wired.com/gadgetlab/2010/07/bloatware-android-phones/">Bloatware on Android Phones</a> and <a href="http://androidspin.com/2012/03/18/remove-bloatware-on-t-mobile-samsung-galaxy-s-ii-phones/">Remove Bloatware from Samsung Galaxy</a></p>

<p>This is also a security risk as even I was tempted to &lsquo;root&rsquo; the phones or allow installation of apps from marketplaces other than the Google Play Store.  Most users are  never going to use a Video Hub or a Social Hub or any other Hub.  And now it is becoming more intrusive.  Hey, I even did not install Kaspersky Mobile as it did not come from Google.</p>

<p>On the Note II, the default SMS software, the default Internet browser and the default Music player are ALL bloatware.  Where&rsquo;s Google in all this?  An open software encourages this behaviour, but the marketplace should have some rules, and why can&rsquo;t I remove software that causes no problems when disabled?</p>

<p>Please, don&rsquo;t let my next phone be an iPhone.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First Looks: IBM SmartCloud Enterprise]]></title>
    <link href="http://www.akber.com/first-looks-ibm-smartcloud-enterprise"/>
    <updated>2012-07-29T19:15:20+01:00</updated>
    <id>http://www.akber.com/first-looks-ibm-smartcloud-enterprise</id>
    <content type="html"><![CDATA[<p><a href="http://www.akber.com/assets/2012/ibm-sce.png"><img src="http://www.akber.com/assets/2012/ibm-sce.png" alt="ibm-sce" /></a></p>

<p>Last year, there was an opportunity to participate in IBM&rsquo;s Cloud Beta and I <a href="http://www.akber.com/ibms-test-and-dev-cloud/">wrote about</a> some initial impressions.</p>

<p>IBM have now rolled this out with geographically dispersed data centres.  Even with some terms being unique to IBM, the provisioning of instances and management of images should be familiar to those who have worked with Amazon&rsquo;s EC2 and related cloud services.</p>

<p>This gives &lsquo;true Blue&rsquo; customers an option to entrust sensitive systems to a cloud provider with whom there is an existing relationship.  It will be interesting to see how this offering from IBM stacks up against managed services from IBM.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Software Testing]]></title>
    <link href="http://www.akber.com/software-testing"/>
    <updated>2012-03-26T00:11:17+01:00</updated>
    <id>http://www.akber.com/software-testing</id>
    <content type="html"><![CDATA[<p><strong>Algorithmic Complexity and the Theoretical Limits of Testing:</strong> According to the undecidability theorem, most software quality properties are not provable. Therefore, what kind of testing techniques do we use to achieve software quality?  While it is theoretically impossible to deterministically test a system for flawless quality, it is possible &mdash; through good design, communications and dynamic testing &mdash; to prevent and detect defects, and to verify and validate the system against pre-defined expectations.</p>

<!-- more -->


<h2>Undecidability Theorem</h2>

<p>The undecidability or incompleteness theorem is a statement of complexity of systems (a group of logical statements when taken together) first formulated by Godel <a href="#references">1</a> &mdash; and is the precursor to Turing&rsquo;s halting theorem about Turing machines &mdash; which in turn is the precursor of modern program-based computer systems. Without going into details, a good summary that serves the current purposes is: <em>any piece of code that&rsquo;s complex enough to be interesting will always surprise its programmers</em> <a href="#references">2</a>.</p>

<p>This concept is generally known as <strong>algorithmic complexity</strong> (AC). In Claim 4 , Lewis successfully uses these theorems to prove that </p>

<blockquote><p><em>There is no estimator which produces a correct fixed bound on the complexity of all inputs.&ldquo;</em>  <a href="#references">3</a>.
The impications of algorithmic complexity do not apply only to software programs, but extend to other areas such as encryption algorithms, computer security, etc.</p></blockquote>

<h2>Testing techniques: origins and types</h2>

<p>So, how do we test software for quality if we assume that we have proven that software can never be completely tested? By &mdash; <strong>prevention, detection, verification</strong> and <strong>validation</strong>. These concepts are fairly generic and subjective, and to make them as objective as possible, a numbe of techniques have been specified by scientists and have evolved in business software development.</p>

<p>In the recent past, these techniques have been refined and assumed greater importance with the advent of distributed software that relies on multiple systems working correctly and as expected in order to fulfil the business goals. In other words, the &ldquo;contractual&rdquo; reliability of the interfaces between disparate software systems has resulted in these techniques coming to the forefront of software development as part of a continuous quality assurance process <a href="#references">4</a>.</p>

<p>Here are the three main groups of these techiques and most of them involve steps <strong>before, during</strong> and <strong>after</strong> the development of software (the foundation of TQM). Both groups involve <strong>static</strong> (without execution) and <strong>dynamic</strong> (execution) testing of programs.</p>

<h3>1. Functional Testing (black-box)</h3>

<p>The developed software system is seen as a black box which is expected to satisfy a set of business requirements. Those requirements are provided to developers as specifications, and once the programs have been partially or completely developed, they are tested against these functional specifications. This testing is sometimes <strong>manual</strong> &mdash; as in user clicking on a GUI and producing results or sophisticated programs can be used to design and quantify the functional tests, and then to measure the software against them.</p>

<p>Functional test generation and execution tools are a fairly recent addition <a href="#references">5</a>. Commonly employed techniques are:
* Acceptance testing: dynamic: where the software testing is tested against user specifications so that the user community &ldquo;accepts&rdquo; it.
* Regression tests: dynamic: when changes in a prior version of the software are tested to make sure that they have not compromised existing functionality.
* Integration testing: dynamic: when separately developed components are testing when they are executing in concert with each other.
* End-to-end testing or transaction testing: a business transaction is tested from beginning to end.
* Inspections: static :when the software is tested for completeness and interaction and functional assumptions are validated by a dialogue between the user community and the development team, usually with a meeting that involves a design of the system.</p>

<h3>2. Structural Testing (white-box)</h3>

<p>These tests delve inside the code of the system and test the logic of individual pieces. It may be necessary to organize the code in a way to make structural testing possible. Almost all of these techniques are <strong>automatic</strong>, using a variety of tools. These tests are NOT exhaustive, i.e. if they were to check for all valid inputs, the number of tests would be astronomical. In real-life, experienced programmers check for bounds, limits, nulls, zeros and other such inputs into &ldquo;units&rdquo; of code. Commonly employed techniques include:
* Unit testing: dynamic: programmatically tests portions of the code against a set of conditions specified by the programmer that developed the software or another programmer. This is further augmented by <em>unit test coverage testing</em> &mdash; testing that tests the extent of the code that is &ldquo;covered&rdquo; by unit testing!
* Code walk-throughs: static : the programmer walks through the logic and branching of the code by him/herself or with the development team &ndash; looking for obvious flaws that are detectable by a &lsquo;second pair of eyes&rsquo;. It is also helpful for junior programmers to learn best practices in coding.
* Branch-condition testing: dynamic : using tools and pre-compilers, the execution of code is tested in conjunction with unit testing (see above) to determine if all the branch conditions in the code have been &ldquo;covered&rdquo;.
* Thread testing: static dynamic: this tests the code for concurrent or &ldquo;race conditions&rdquo;. Such tests are notoriously hard to design due to the unpredictability of such conditions and good design is always a must, and as such, I classify them as &lsquo;static&rsquo; also.</p>

<h3>3. Operational Testing</h3>

<p>These types of testing test the software under operational conditions. Examples include:
* Stress testing: dynamic : testing the software under operational loads that exceed the maximum expected loads on the system.
* Security breach testing: static and dynamic: testing the software under a combination of real-world security risks.</p>

<h3>Combination of Techniques (gray-box), and Risk Analysis</h3>

<p>A good testing regimen is a combination of functional and structural testing as well as operational testing. This has been referred to as &ldquo;gray-box&rdquo;! However, the choice of the exact techniques to use depends on an experienced <strong>risk analysis</strong> of the business impact of software defects in terms of financial loss and prestige loss (sometimes it is the same thing). For example &ndash; what is the business impact of a bank account statement being sent to the wrong person? What is the impact of a delayed product shipment? etc.</p>

<p><a name="references">&nbsp;</a></p>

<h2>References</h2>

<ol>
<li><a href="http://users.ox.ac.uk/~jrlucas/Godel/mmg.html">R. Lucas: Minds, Machines, and Gödel. Philosophy XXXVI (1961):112-127, retrieved on 18 September, 2005.</a></li>
<li><a href="http://www.awprofessional.com/articles/article.asp?p=101654">Mitchell Waldrop, Complexity: The Emerging Science at the Edge of Order and Chaos, Simon and Schuster, 1992, 282. , retrieved on 18 September, 2005.</a></li>
<li>JP Lewis, Limits to Software Estimation, ACM SIGSOFT, Volume 26 Issue 4 July 2001, p. 58.</li>
<li>W Lewis, Software Testing and Continuous Quality and Improvement, 2nd Edition, pp. 29-39.</li>
<li><a href="http://www-306.ibm.com/software/awdtools/tester/functional/index.html">Functional Testing: http://www-306.ibm.com/software/awdtools/tester/functional/index.html</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Program Management]]></title>
    <link href="http://www.akber.com/program-management"/>
    <updated>2012-03-25T14:11:36+01:00</updated>
    <id>http://www.akber.com/program-management</id>
    <content type="html"><![CDATA[<p>Program Management, a discipline that has been around for a long time (as in &lsquo;social programs&rsquo;), is gaining wider acceptance as IT projects become more complex, inter-related and closer to the actual business processes that they help to run. In other words, projects may fail to deliver their benefit due to no intrinsic failure of the project itself. The project delivers a product, whereas the program delivers the benefit.</p>

<!-- more -->


<h2>Introduction</h2>

<p>Program Management is the art of providing a total benefit out of related projects &mdash; at a certain cost and at a specified risk tolerance.</p>

<p>Let us look at an example, the repaving of a road for two kilometres is a discrete project that can be executed by a contractor in return for a certain payment.  However, the funds and schedule for that project may have come from a &lsquo;City Infrastructure Improvement Program&rsquo;.  Ten individual road may have been fixed, but did the infrastructure of the city actually improve?  Was the benefit of &lsquo;infrastructure improvement&rsquo; actually realized? How can it be measured?</p>

<h3>Why Programs?</h3>

<p>Here, we can make a rebuttable assumption that programs are initiated due to one of these three reasons: a vision, a business need, or regulatory compliance.  A vision can be justified as a business case, but it remains a vision due its specificity.  A town aiming to become the &lsquo;tourist capital&rsquo; of a state is a vision &ndash; it could have just as easily made a business case for becoming a &lsquo;festival capital&rsquo; or an &lsquo;education capital&rsquo;.  A question I am fond of presenting is: why should we build Ugly Bridge over Muddy River? The King thinks another bridge will look pretty, or the capacity of the current bridge has already been exceeded, or the public safety authority is about to condemn it because it is not safe.  Each of these reasons belongs to each of the categories: vision, need, or regulation.</p>

<h3>Isn&rsquo;t this just Business as Usual?</h3>

<p>Well, if program management is sounding almost like running a business, it may well be.  Let me present another hypothesis: every transition in the state of a business is a program.  A static business that is not growing or shrinking, and where every day is BAU (business as usual), is not in need of a program. As soon as it embarks on growing its customer base (going international) or shrinking (downsizing), a bunch of inter-related projects appear out of nowhere.  What about translation, re-training, customer service levels, IT systems etc.  Now, all of these projects may be individually successful, but the benefit of international expansion or downsizing may never be realized.  This is where Program Management comes in.</p>

<p>So, Program Management is part of Business Transition Management or Change Management.</p>

<p>Quite a few companies have adopted Program Management across their organizations.  A recently launched bank (that used to be my client) have based their entire organizational structure under the umbrella of the Program Management Office. The structured and rigorous methodologies of Program Management drove their launch, their expansion, and the transition of their core processes to different types of financial service offerings.</p>

<h2>Methodologies</h2>

<p>There are two main methodologies that are widely followed:
1. <a href="http://www.pmi.org/CareerDevelopment/Pages/Our-Credentials.aspx#pgmp">PMI PgMP Credential Exam Methodology</a> builds on PMI&rsquo;s PMBOK-based methodology of phases, planning and control, and naturally lends itself more to quantifiable change management (need and regulation drivers).
2. <a href="href='http://www.best-management-practice.com/Knowledge-Centre/Best-Practice-Guidance/Managing-Successful-Programmes/">OGC Managing Successful Programmes</a> builds on the PRINCE2 document-centric methodology of management by exception.  Its planning approach is iterative and more conducive to programs where the start is just a one-sentence mission statement (vision driver).</p>

<p>The following roles and responsibilities are common to both, and to others as well:
* Sponsor &ndash; to put it blungly, the person who may lose their job if the benefit is not realized
* Advisory Board &ndash; members with insight into various business areas affected
* Program Manager &ndash; the executor of the program with an eye on projects and benefits
* Change Co-ordinator &ndash; facilitates the adoption of the changed products and processes</p>

<h2>Program Management in IT</h2>

<p>While Program Management is a generic discipline, its recent emergence has fulfilled a growing need.  Around the turn of the century, projects building or improving modern complex and distributed computer systems were experiencing a <a href="http://www.spectrum.ieee.org/sep05/1685">very high rate of failure</a>. The situation has <a href="http://www.softwaremag.com/L.cfm?doc=newsletter/2004-01-15/Standish">improved somewhat</a> in the last few years, primarily due to a focus on infrastructure and software architecture, solid program and project management, Internet-enabled information sharing, the open-source movement, and iterative software development methodologies.  Program Management for software systems is particularly useful over multiple systems, disparate geographies and disjointed business units.</p>

<p>With distributed systems, especially those based on, or transitioning to,  SOA (Service-Oriented Architecture), it is now possible for business process applications to be the composition and orchestration of discrete services, put together by relatively non-technical people.  This business agility and flexibility comes at the cost of inter-dependent services and systems that form a grid-like virtual business world that is perhaps equal in nuance to the real business processes that it drives.  The responsiveness of systems to business change goes the other way too:  the business is now ulta-sensitive to change in systems. Implementing and changing such systems cannot be big-bang, and cannot be simple projects, <a href="http://www.soamag.com/I17/0408-3.asp">they need to be programs</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Overview of ITIL-based Application Backup and Recovery]]></title>
    <link href="http://www.akber.com/overview-of-itil-based-application-backup"/>
    <updated>2012-03-25T14:11:36+01:00</updated>
    <id>http://www.akber.com/overview-of-itil-based-application-backup</id>
    <content type="html"><![CDATA[<p><em>Derived from a subset of IT Service Continuity Management (ITIL v3 ITSCM):</em> ITIL v3 ITSCM considers application backup and recovery as one of the risk mitigating factors in assuring service continuity. This is a brief discussion of commonly understood IT application backup and recovery methods within the ITIL v3 ITSCM framework.</p>

<!-- more -->


<p>In ITIL v3, ITSCM (IT Service Continuity Management) is defined as:</p>

<blockquote><p><em>‘The goal of ITSCM is to support the overall Business Continuity Management process by ensuring that the required IT technical and service facilities (including computer systems, networks, applications, data repositories, telecommunications, environment, technical support and Service Desk) can be resumed within required, and agreed, business timescales.’ (ITIL v3 ITSCM 4.5.1)</em></p></blockquote>

<p>Within each of the four stages of ITSCM, backup and recovery planning and the testing and invocation of its procedures, is mapped as follows:</p>

<h2>Stage 1 &ndash; Initiation</h2>

<blockquote><p><em>Resource allocation: Depending on the maturity of the organization, with respect to ITSCM, there may be a requirement to familiarize and/or train staff to accomplish the Stage 2 tasks. Alternatively, the use of experienced external consultants may assist in completing the analysis more quickly. However, it is important that the organization can then maintain the process going forward without the need to rely totally on external support. (ITIL v3 ITSCM 4.5.5.1)</em></p></blockquote>

<p>In other words, the ultimate ownership of the backup and recovery strategy and processes lies with the organization itself.</p>

<h2>Stage 2 &ndash; Requirements and Strategy</h2>

<p>Once the Business impact Analysis and Risk Analysis has been done, backup and recovery of applications and data is usually one of many Risk Response Measures.</p>

<blockquote><p><em>A comprehensive backup and recovery strategy, including off-site storage. (ITIL v3 ITSCM 4.5.5.2)</em></p></blockquote>

<p>The recovery procedures are defined first, and then backup procedures and their frequency are based on the needs of the recovery procedures.</p>

<p>Common recovery options include:
1. <strong>Cold Standby</strong> (Gradual Recovery): Servers need to be reconfigured and applications deployed, and this can take days or weeks.
2. <strong>Warm Standby</strong> (Intermediate Recovery): From minutes to a few hours, this option requires servers and applications already configured and deployed, that need to be connected to the production infrastructure (using network or other techniques. By engaging a third party to host alternate hardware, this technique can also be used for disaster recovery.
3. <strong>Hot Standby</strong> (Immediate or Fast Recovery): This option requires redundant hardware and applications that may or may not be at the same physical location, which automatically take over, without minimal interruption to IT services.</p>

<h2>Stage 3 &ndash; Implementation</h2>

<p>In this stage, backup and recovery processes are implemented using one or more of the following types of tests:
1. Theoretical Testing: Concerned individuals meet to assess the effectiveness of the backup and recovery procedures
2. Announced and unannounced full testing: this is a full dress rehearsal.
3. Partial testing and event-based testing: this is a subset of full testing.</p>

<h2>Stage 4 &ndash; Ongoing Operations</h2>

<blockquote><p><strong>Testing</strong> – <em>following the initial testing, it is necessary to establish a programme of regular testing to ensure that the critical components of the strategy are tested, preferably at least annually, although testing of IT Service Continuity Plans should be arranged in line with business needs  &hellip;  All plans should also be tested after every major business change. (ITIL v3 ITSCM 4.5.5.4)</em></p></blockquote>

<p>Recovery Invocation
When disaster strikes, the organization needs to put the recovery plans into action:
* Retrieval of backup tapes, data documentation, procedures, software images etc. from on-site or off-site locations
* Mobilization of the appropriate technical personnel to commence the recovery of required systems, servers, applications and services
* Contacting and putting on alert customers, partners, service providers, application vendors, etc. who may be required to undertake actions or provide assistance in the recovery process</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ubuntu as a First-Choice Desktop OS]]></title>
    <link href="http://www.akber.com/ubuntu-as-a-first-choice-desktop-os"/>
    <updated>2012-01-29T17:55:00+00:00</updated>
    <id>http://www.akber.com/ubuntu-as-a-first-choice-desktop-os</id>
    <content type="html"><![CDATA[<p>Working with Linux desktops for about 15 years now, I am always preparing for workarounds and compromises when using Linux for day-to-day desktop work.</p>

<!-- more -->


<p>Our new Canon MP-series printer/scanner/copier was to be used for scanning and colour printing.  We would plug it into the Ubuntu desktop for printing and we thought that the scanning would only work on a Windows machine.  Just before our admin was about to put in the manufacturer&rsquo;s CD into a Windows laptop for the occasional scanning, I  plugged in the USB cable into the Ubuntu 11.10 desktop and was delighted to find out that the printer was automatically detected and configured.  Feeling brave, I typed &lsquo;scan&rsquo; into the Ubuntu Unity menu and up came an app that appeared to be rather spartan.  I felt brave and clicked &lsquo;scan&rsquo;.</p>

<p>It scanned and allowed me to crop the image.  I scanned another sheet, cropped it different dimensions, and then saved to PDF, half-expecting it to create two documents.  Both sheets came out as two pages of a very fine PDF file.  Amazing, without installing any software and having to use manufacturer-supplied bloatware.</p>

<p>Now, if only Ubuntu would establish an MTP connection with my Android.</p>

<p>Maybe Ubuntu&#8217;s <a href="https://bugs.launchpad.net/ubuntu/+bug/1">Bug #1</a> will finally get resolved.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Apps and Blackberry-style Device Wipes]]></title>
    <link href="http://www.akber.com/google-apps-and-blackberry-style-device-wipes"/>
    <updated>2012-01-29T17:44:00+00:00</updated>
    <id>http://www.akber.com/google-apps-and-blackberry-style-device-wipes</id>
    <content type="html"><![CDATA[<p><a href="http://www.akber.com/assets/2012/remote-wipe.jpg"><img src="http://www.akber.com/assets/2012/remote-wipe.jpg" alt="" /></a></p>

<p>Google is changing and maturing as a corporation, and has recently missed an earnings target.  Rumours abound that Google may be turning &lsquo;evil&rsquo;.  However, I stumbled on to some features that Google has added to its &lsquo;Apps&rsquo; offering that negate that perception.  I use Google Apps for our consultants &mdash; the shared contacts, docs, calendar and email delegation come in very handy.  All these features can be found in Microsoft Exchange or IBM Lotus Notes, but these collaboration suites may not be cost-effective for a small company.</p>

<!-- more -->


<p>One of the worries was the access to Google Apps from our Android devices in the unfortunate event of a device being lost or stolen.  Thanks to the &lsquo;<a href="https://market.android.com/details?id=com.google.android.apps.enterprise.dmagent&amp;hl=en">Google Apps Device Policy</a>&rsquo; Android app, I can now set device policies from the Apps administration menu for all employees who access Google Apps.  We&rsquo;ve not had to block or wipe a device yet, but it is comfortable knowing that it can be done.</p>

<p>Now, Blackberry has had that for ages as part of its corporate offerings, but again, what&rsquo;s a small company to do?</p>

<p>It was easy to set up and test, with the only hurdle in implementing our desired policy being the fact that some Android devices do not support data encryption.  Maybe we have to look further and install some software or set some options, but we are good for now.</p>

<p>With two-factor authentication, emergency two-factor codes and now remote Android device wipe, small companies like ours can now have peace of mind.  Combine this with the data liberty features of Google Apps, and Google is not evil &mdash; yet!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting Up the RDS Database Instance]]></title>
    <link href="http://www.akber.com/setting-up-the-rds-database-instance"/>
    <updated>2011-12-12T23:10:00+00:00</updated>
    <id>http://www.akber.com/setting-up-the-rds-database-instance</id>
    <content type="html"><![CDATA[<p><strong>Update:</strong> Amazon AWS RDS can now be configured from the AWS Web console</p>

<!-- more -->


<p>Although the RDS is a service and we are not supposed to think of it as a machine, it is just like an EC2 instance.  We have to use the command-line tools, as RDS instances &mdash;do not show up under&mdash; the <a href="https://console.aws.amazon.com/ec2/home">EC2 console</a> <em>(they do as of 2010-05-26)</em> or in other tools like <a href="http://developer.amazonwebservices.com/connect/entry.jspa?externalID=609">ElasticFox</a>.  This toolkit should run on your local machine, and without going into too much detail, please make sure that the following environment variables are set &mdash; here is an excerpt of a shell script that I use to set up my RDS environment and I run it in the folder where I unzipped the <a href="http://developer.amazonwebservices.com/connect/entry.jspa?externalID=2928">RDS command-line tools</a></p>

<div>
  <pre><code class='html'>export AWS_RDS_HOME=`pwd`
export JAVA_HOME=/usr/lib/jvm/java-6-openjdk/jre
export AWS_CREDENTIAL_FILE=~/.ec2-credential-file
export PATH=$PATH:$AWS_RDS_HOME/bin
export EC2_REGION=eu-west-1b</code></pre>
</div>


<p>Note that there a few ways to access Amazon Web Services, one of which uses the access key and credentials, and  I leave my credentials file hidden in my home folder.  It should look like this:</p>

<div>
  <pre><code class='html'>AWSAccessKeyId=AAAAAAAAAAAAAAAAAAAAAAAAAA
AWSSecretKey=ZZZZZZZZZZZZZZZZZZZZZZZZZzZZ</code></pre>
</div>


<p>Note that redundancy is provided through automated backups, retention periods, snapshots, and multi-AZ (availability zones) provided by the Amazon AWS Cloud itself.</p>

<p>We will create the RDS instance, change some server parameters and allow access to it from the cloud instance(s) that will run the application:<br/></p>

<div>
  <pre><code class='html'>rds-create-db-instance ZZZZZ --allocated-storage NN --db-instance-class db.m1.small --engine MySQL5.1 --master-username MMMM --master-user-password xxxxxxxxxx --backup-retention-period 7 --availability-zone eu-west-1b --headers

# WAIT UNTIL INSTANCE IS CREATED (use rds-describe-db-instances to view progress)

# Set up server for UTF-8 operations
rds-create-db-parameter-group utf8 --engine mysql5.1 --description &quot;Parameters for UTF-8&quot;
rds-modify-db-parameter-group utf8 --parameters=&quot;name=character_set_server, value=utf8,method=immediate&quot;
rds-modify-db-instance appsdb --db-parameter-group-name utf8

# Reboot the instance
rds-reboot-db-instance appsdb

#WAIT UNTIL parameters are applied and reboot is complete

# Allow access from the EC2 application instances.  We assume that we arleady have an EC2 security group called apps.  It can be anything, and contain anything, as long as it is the security group that is (or will be) applied to the apps cloud instances:

rds-authorize-db-security-group-ingress Default --ec2-security-group-name apps --ec2-security-group-owner-id 999988881111

# Ensure that all went well.  Some columns have been ommitted.  Make a note of the DNS names.  The mySQL client and the applications will refer to it
rds-describe-db-instances --headers
DBINSTANCE  DBInstanceId   ~~~~  Status     Endpoint Address                          Port  AZ          Backup Retention  Multi-AZ
DBINSTANCE  social               available  appsdb.xxxxx.eu-west-1.rds.amazonaws.com  3306  eu-west-1b  7                 n       
      SECGROUP  Name     Status
      SECGROUP  default  active
      PARAMGRP  Group Name  Apply Status
      PARAMGRP  utf8        in-sync</code></pre>
</div>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Resilient Crowd, Jira and Confluence on Amazon EC2 and RDS]]></title>
    <link href="http://www.akber.com/resilient-crowd-jira-confluence-amazon-ec2"/>
    <updated>2011-12-11T23:10:00+00:00</updated>
    <id>http://www.akber.com/resilient-crowd-jira-confluence-amazon-ec2</id>
    <content type="html"><![CDATA[<p><strong>This page is out-of-date.</strong>  Atlassian has come out with cloud pay-as-you-go pricing <a href="http://www.atlassian.com/software/ondemand/overview">(OnDemand)</a> which is now recommended instead of the 10-user license mentioned below.</p>

<!-- more -->


<p>These are three tools that I cannot do without, and thanks to new Atlassian licensing options, I don&rsquo;t have to do without them.  Based on emerging cloud philosophy, I don&rsquo;t want to worry about routine things, and will let the cloud take care of as much as possible. Keeping this principle in mind, let us look at our topology:</p>

<ol>
<li>Assume DNS and LDAP exist somewhere &mdash; out of scope of this discussion.  DNS and LDAP are the keys to the kingdom, and healthy paranoia dictates that they are hosted separately.</li>
<li>Our data would be stored in a small <a href="http://aws.amazon.com/rds/">Amazon RDS</a> instance, which is basically a MySQL machine with controlled parameters and access.  We do not want to worry about backups, standbys etc.  Let the cloud take care of it.</li>
<li>For the four applications that we are going to deploy, we will use an existing Linux distribution that can be booted off a virtual disk and can be saved back to it!  Amazon calls this an <a href="http://aws.amazon.com/ebs/">EBS (Elastic Block Storage)</a> <a href="http://en.wikipedia.org/wiki/Amazon_Machine_Image">AMI (Amazon Machine Image)</a>.  Ubuntu is very serious about the cloud and we will use its 10.04 (Lucid Lynx) EBS image as a starting point.  Since we are going with a small machine, and they are only available in 32-bit yet, we will go for the <a href="http://developer.amazonwebservices.com/connect/entry.jspa?externalID=3102">Ubuntu 10.04 32-bit server</a>.</li>
</ol>


<p>I will try to keep things at an intermediate complexity level, so that even if you are not familiar with the Amazon Cloud, you can follow along, and clarify concepts by clicking on the links.  Also, based on security principles (and the secure <a href="http://aws.amazon.com/mfa/">multi-factor authentication</a> by Amazon), any techniques that you may have learned in which you put your access keys on one cloud machine in order to access another, should be forgotten.</p>

<ol>
<li><strong>Principle 1:</strong> Let the cloud handle as many routine things as it can, and follow its lead instead of fighting with it.</li>
<li><strong>Principle 2:</strong> Your access key, secret key and certificate private key should be with you, and never on any cloud machine.</li>
<li><strong>Principle 3:</strong> Unless you need redundancy and serving speed on a global scale, or you want to hedge against your Cloud provider melting down, keep all your cloud instances in one availability zone.</li>
</ol>


<p>If you do not have one, create an EC2 account, and get yourself &mdash;
* Two elastic IPs,
* One Security Group called &lsquo;apps&rsquo; in addition to the default one, and
* an EBS volume for your app data (50 GB is a good start) called <code>/dev/sdf</code>.</p>

<p>The pages below contain the general technical flow and discussion and, in addition, I will try to mention how redundancy and reliability can be designed and built into the topology.  In this way, the system administrator&rsquo;s approach to availability and performance becomes different and less complex.</p>

<p>Next: <a href="http://www.akber.com/architecture/2011/12/12/setting-up-the-rds-database-instance/">Setting up the RDS Database Instance</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The App Is King]]></title>
    <link href="http://www.akber.com/the-app-is-king"/>
    <updated>2011-10-27T15:41:00+01:00</updated>
    <id>http://www.akber.com/the-app-is-king</id>
    <content type="html"><![CDATA[<p>Networks, storage, and all other information technology infrastructure are fairly complicated things and it takes substantial planning and flawless execution to get it right.</p>

<p>Project managers and analysts do great work to ensure that what runs on these infrastructure systems is properly specified and delivered on time.</p>

<p>And with all this hard work, and whether data is delivered over 4G mobile or 10G ethernet, all that users see is the App.  Nothing matters if the app is not there when the user wants it, and how the user wants it.</p>

<p>The App is King.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IBM Finally Gets It With WebSphere 8.5 'Liberty']]></title>
    <link href="http://www.akber.com/ibm-finally-gets-it-with-websphere-8-5-liberty"/>
    <updated>2011-10-16T10:10:00+01:00</updated>
    <id>http://www.akber.com/ibm-finally-gets-it-with-websphere-8-5-liberty</id>
    <content type="html"><![CDATA[<p>Finally!  Some long-needed innovation in WebSphere application servers from IBM, and some fresh thinking that may boost the long-term viability of IBM leadership in middleware software.</p>

<!-- more -->


<p>Whether it is the pressure from Oracle or open-source innovation, or a long-overdue grounds-up overhaul of the WebSphere application server architecture that has been stagnant since version 5.0 &mdash; it is looking good.  A start-up time of 5 seconds, grounds-up OSGI with optional features, drop-in deployments and no installer with a zip file of under 50MB.  No installer!  At least in the alpha version that we had a chance to preview today.</p>

<p>There is still a lot to be done with the version numbering.  What is this thing about releasing major technology refreshes on a minor version number?  8.0 was really 7.0+  and 6.1 was a step up from 6.0.  The desire to have a common version number across the WebSphere family really did not go anywhere.  We have Lotus Quickr 8.1 on WebSphere 6.0 and Portal 7.0 on WebSphere 6.1 and the list goes on.  Sometimes, a version refresh of WebSphere was that &mdash; a version refresh.  And don&rsquo;t get me started on the dubious software strategy of the same product on two completely different technology platforms &mdash; the infamous Quickr &mdash; the less said about the Portal version the better.</p>

<p>1998-2004 was a period of great innovation in IBM software, and it has pretty much been stagnant since then. Sometimes it appears that the a flock of MBA-types swooped in and milked the software and all its permutations and all kinds of incremental functionality packaged and marketed as &lsquo;servers&rsquo;.  There was little innovation in the past five years &mdash; so little that even die-hard IBM fans were looking elsewhere to fulfil their Web 2.0 application needs.</p>

<p>On another note, the HTML-only Sametime client was also a long time coming, but it is a welcome presence now that it is here.  How could IBM have missed the use cases for extranet communication and click-to-chat customer service?</p>

<p>Enough criticism.  Keep up the good work, Big Blue.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ITIL, PRINCE2 and Agile]]></title>
    <link href="http://www.akber.com/itil-prince2-and-agile"/>
    <updated>2011-04-11T00:10:00+01:00</updated>
    <id>http://www.akber.com/itil-prince2-and-agile</id>
    <content type="html"><![CDATA[<p>Enterprise systems required service management to ensure that newly deployed projects run in a predictable and manageable manner.  The discipline and project managment that enabled project delivery should continue in some form.  The project has now become a service and service management picks up from project management, preferably with due protocol and acceptance.  </p>

<p><a href="http://www.itil-officialsite.com/">ITIL</a> is a widely used standard for service management.  Large organisations that use ITIL typically would use PRINCE2 as the project management methodology to enable project delivery within known budgets and timelines.  Agile development methods are proving to be better at providing quality, meritocracy and skill rentention in software development.</p>

<p>At one client, we had the challenge of explaining how these will all work together.  Here is the sketch I used (with permission):</p>

<!-- more -->


<p><img src="http://www.akber.com/assets/2011/itil-p2-scrum.jpg" alt="" /></p>

<ul>
<li>Agile development techniques are used to build and deliver components that correspond to a PRINCE2 work package. These are termed &lsquo;Dev&rsquo; scrums.</li>
<li>Agile &lsquo;sprints&rsquo; or &lsquo;scrums&rsquo; are also used to build configurations (environments, scripts, tests) etc. that are required for ITIL service transition and acceptance. These are termed &lsquo;IT&rsquo; sprints.</li>
<li>A PRINCE2 stage lifecycle should align with the service delivery cycle.</li>
</ul>


<p>This approach helped us to find issues earlier and align delivery of developed components and infrastructure as a coherent service that could then be taken over by service management.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OOO - Happy 10th Birthday]]></title>
    <link href="http://www.akber.com/ooo-happy-10th-birthday"/>
    <updated>2010-10-15T13:18:00+01:00</updated>
    <id>http://www.akber.com/ooo-happy-10th-birthday</id>
    <content type="html"><![CDATA[<p>Happy birthday to OpenOffice, also known as OpenOffice.Org and their contribution to the standardisation of the ODF standards and providing a viable alternative to an entrenched market leader.  Reminds us of the browser wars of the early 2000s.</p>

<p><a href="http://wiki.services.openoffice.org/wiki/A_Brief_History_Of_OpenOffice.org">http://wiki.services.openoffice.org/wiki/A_Brief_History_Of_OpenOffice.org</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linking Dialog and Web Activities in WebSphere Commerce Marketing]]></title>
    <link href="http://www.akber.com/linking-dialog-and-web-activities-in-websphere-commerce-marketing"/>
    <updated>2010-10-15T00:10:00+01:00</updated>
    <id>http://www.akber.com/linking-dialog-and-web-activities-in-websphere-commerce-marketing</id>
    <content type="html"><![CDATA[<p>IBM WebSphere Commerce 7.0 comes with a substantial set of marketing activities, namely web activities, e-mail activities and dialog activities.  These are all part of a feature known as &lsquo;Precision Marketing&rsquo; which works roughly as follows:</p>

<p>An active customer action or a background processing action causes a &lsquo;trigger&rsquo; to fire.  If this triggering can be scoped to a &lsquo;target&rsquo; (qualification), then an &lsquo;action&rsquo; occurs. </p>

<p>Activity types: Web and e-mail activities push content along, while dialog activities respond to specific shopper request behaviour.</p>

<p><strong>Poor Man&rsquo;s Recommendation Engine:</strong> Now, a recommendation engine pushes content and products based on past shopper behaviour, whether specific to that shopper, or general past shopper behaviour.</p>

<p>If a dialog activity&rsquo;s end action is to persist captured user behaviour, then triggers and targets based on the persisted behaviour can then be used in a web activity to display specific content.</p>

<p>Thus, combining the two with some custom enhancements that put together some logic and data storage and you may have a specialised recommendation engine for your specific business needs.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IBM's Test and Dev Cloud]]></title>
    <link href="http://www.akber.com/ibms-test-and-dev-cloud"/>
    <updated>2010-05-20T09:33:00+01:00</updated>
    <id>http://www.akber.com/ibms-test-and-dev-cloud</id>
    <content type="html"><![CDATA[<p>IBM is beta-testing its own cloud at <a href="https://www-180.ibm.com/cloud/enterprise/beta/dashboard">https://www-180.ibm.com/cloud/enterprise/beta/dashboard</a>, after a successful experiment with Amazon EC2.</p>

<p>As a company with hardware and operating system roots, it was smart to get on to the cloud bandwagon, which is essentially the commoditization of hardware and operating systems.</p>

<p>A plain Suse instance was not a problem. However, after some initial trouble launching a WebSphere Portal/WCM instance in the wrong-sized machine, I was able to launch an instance in a &lsquo;small&rsquo; machine. I only tried it once, but a WebSphere sMash instance did not launch. My first impression is good &mdash; for a beta-testing environment, and quick proofs of concept, it is very handy.</p>

<p>If you know Amazon EC2, the management console should be pretty much intuitive. The only time I had to read the good online help was when I needed to know the exact user to be used for the SSH session into an instance.</p>

<p>Let us wait and see how IBM manages to position this offering once it is out of beta.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Google Calendar Link Shows Google's Strong URL Architecture]]></title>
    <link href="http://www.akber.com/google-calendar-link-shows-googles-strong-url-architecture"/>
    <updated>2010-05-02T11:55:00+01:00</updated>
    <id>http://www.akber.com/google-calendar-link-shows-googles-strong-url-architecture</id>
    <content type="html"><![CDATA[<p>Quick Post:  Just tried this today and it worked:</p>

<p>Travel and meeting sites can give you a link that can add an entry to your Google Calendar, among ICAL and other links thare are also provided.  This is very handy, as it takes care of time zones etc. and works out quite well.  The link is usually of the type:</p>

<blockquote><p><a href="http://www.google.com/calendar/event?action=TEMPLATE&amp;text=.">http://www.google.com/calendar/event?action=TEMPLATE&amp;text=.</a> &hellip; .</p></blockquote>

<p>If you are on your company&rsquo;s Google Apps hosted calendar, this link would not work and it would ask you to log in to a regular google account, not a Google Apps for Business calendar.  If you copy the link location and add after &lsquo;calendar/&rsquo;:</p>

<blockquote><p><a href="http://www.google.com/calendar/hosted/xxxx.com/event?action=TEMPLATE&amp;text=.">http://www.google.com/calendar/hosted/xxxx.com/event?action=TEMPLATE&amp;text=.</a> &hellip; .</p></blockquote>

<p>where &lsquo;xxxx.com&rsquo; is your Google Apps domain, it works like a charm. Kudos to Google URL architecture and those that enforce it.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Third Generation eCommerce]]></title>
    <link href="http://www.akber.com/third-generation-ecommerce"/>
    <updated>2010-02-22T22:15:00+00:00</updated>
    <id>http://www.akber.com/third-generation-ecommerce</id>
    <content type="html"><![CDATA[<p>If the first generation of eCommerce was the shopping cart, and the second wave was enabling all sales channels in addition to on-line sales, then we are now beginning a new trend: the creation of an ecosystem around offered products and services.</p>

<p><a href="http://files.dgwave.com/wp/2010/02/3g.jpg"><img src="http://files.dgwave.com/wp/2010/02/3g.jpg" alt="3g" /></a></p>

<p>While the term &lsquo;social commerce&rsquo; is still being refined, it is becoming apparent that with a wide portfolio of products there is a need to facilitate the interaction of communities &mdash; vendors, customers, and even random visitors &mdash; with your web presence.  It has long been realised that knowledge within a company needs to be unlocked and made accessible to all its employees.  The current challenge is that the same knowledge, if marshalled in the right way, can enable internal and external communities to use it, build upon it and add to it, thereby positioning your products in the proper context in the right ecosystem.</p>

<p>Doing so in a cost-effective manner and with tangible results remains the challenge.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Proposal Submission and Management System on Atlassian JIRA]]></title>
    <link href="http://www.akber.com/atlassian-jira-as-a-workflow-platform"/>
    <updated>2009-11-07T23:10:00+00:00</updated>
    <id>http://www.akber.com/atlassian-jira-as-a-workflow-platform</id>
    <content type="html"><![CDATA[<p><strong>An Issue is an Issue</strong> : Alassian JIRA is all about issues.  In fact, Atlassian sends out T-shirts saying &lsquo;Because you&rsquo;ve got issues&rsquo;!  We first started using JIRA in a purely development support role, but then we read a case study from a company that was using JIRA for their new-hire orientation process.  </p>

<p>We had a particularly challenging project that had a three-month implementation plan (which we took rather seriously), and which required a fairly sophisticated workflow.  The requirements called for researchers (end users) submitting research proposals under multiple disciplines which went through a combined workflow, then an approval particular for for the specific discipline that included external reiewers, and then again through a combined workflow for final granting or rejection.</p>

<!-- more -->


<h2>Software Stack for the Solution</h2>

<p>The client and the project team had chosen <a rel='nofollow' href='http://seamframework.org/'>JBoss Seam</a> as the front-end, primarily due to its close integration with JBoss application server and jBPM as well as the Drools rules engine, but also due to the <i>portletbridge</i> API that allowed a Seam application to run inside JBoss Portal.  Developing with an agile methodology, we were still undecided whether we were going to use jBPM for the actual workflow or come up with something else.  As the requirements poured in, it became apparent that a number of persistence, data, security and administration interaction artefacts would have to be developed in order to support the workflow in jBPM. </p>

<br/>


<br/>


<p>As you may have guessed by now, we decided to use JIRA as the workflow back-end:  end users would access the Seam application, which would use JIRA through its Web Services API for workflow and persistence.  The original user interface of JIRA would be modified using string replacements to provide the administration interface.  Persistence and file attachments were transparent.  It would work!</p>

<h2>Interface Customisation</h2>

<p>Projects and sub-projects became &lsquo;research disciplines&rsquo;, issues became &lsquo;research proposals&rsquo;, and releases became &lsquo;call for papers&rsquo;. The OSWorkflow engine proved to be very flexibile, and transition screens provided the approval input.</p>

<h2>Identity Integration</h2>

<p>So far, so good!  Now came some tricky security issues:
* External users (researchers) were being authenticated by a distributed authentication mechanism, and their user id was provided to the front-end application.  By setting up a trusted symmetric key between the front-end application and JIRA, existing users could be looked up and new users created in JIRA.
* When new users logged in to the front-end, they would be automatically logged in to JIRA using the SOAP API client, with a custom algorithm that bypasses the regular credential check (database password), substituting it for another type of credential check.  This was implemented as another authentication Java class similar to the LDAP authentication Java class that ships with JIRA.  This type of login would only be valid when coming through the SOAP API, in order to avoid inadvertent end-user authentication on the back-end administration interface should they have physical or network access to the administration interface.
* Finally, on the back-end administration interface, a &lsquo;real&rsquo; administrator login (user and password in database) would still be authenticated due to the built-in JIRA login architecture that goes through all possible authenticators one by one.</p>

<h2>Seam Integration and Testing</h2>

<p>The SOAP client derived  from the JIRA WSDL was wrapped in Seam components:
* a UserClient &ndash; that held the authentication token for the logged-in user.
* an AdminClient &ndash; extending the UserClient, but holding an administration login token in order to create new users or look up existing users, and perform other administrative functions through the SOAP API.</p>

<p>Both of these clients were extended into &lsquo;mock&rsquo; scope components in Seam in order to simulate a back-end JIRA using a couple of HashMaps embedded within the mock clients.  This allowed the front-end developers to progress rapidly with their work while not depending on back-end JIRA configuration that was proceeding at its own pace.  For example, when the front-end created a proposal (issue) and called the API to persist it, the mock client would just store the RemoteIssue object into a HashMap keyed by the issue ID.  All subsequent calls to the mock client using that key would retrieve the same RemoteIssue object.</p>

<p>Drop us an email (address on main page of this site) for the source code for the mock JIRA service.</p>

<p>This was a somewhat unorthodox use of JIRA, but this approach resulted in a robust, scalable and feature-rich platform.  The unlimited-user license for JIRA is an expense, but replicating the features of the system would be at an even greater cost.  The system was deployed in February 2009 at <a rel='nofollow' href='https://www.trc.gov.om/portal/sec/portal/default/TRESS'><a href="https://www.trc.gov.om/portal/sec/portal/default/TRESS">https://www.trc.gov.om/portal/sec/portal/default/TRESS</a></a></p>
]]></content>
  </entry>
  
</feed>
